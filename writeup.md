
---

**Vehicle Detection Project**

The goals / steps of this project are the following:

* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images 
* Apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector. 
* Train a classifier - Linear SVM classifier
* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.
* Run pipeline on a video stream and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.


[//]: # (Image References)
[image1]: ./output_images/car_not_car.png
[image2a]: ./output_images/HOG_example_1.jpg
[image2b]: ./output_images/HOG_example_2.jpg
[image2c]: ./output_images/HOG_example_3.jpg
[image2d]: ./output_images/HOG_example_4.jpg
[image3a]: ./colorspace_exploration/000275.png
[image3b]: ./colorspace_exploration/HSV_3D_plot.png
[image4a]: ./output_images/test1.jpg
[image4b]: ./output_images/test2.jpg
[image4c]: ./output_images/test3.jpg
[image4d]: ./output_images/test4.jpg
[image4e]: ./output_images/test5.jpg
[image4f]: ./output_images/test6.jpg
[image5]: ./car_detection2.gif "Video"
[video1]: ./car_detection2.mp4

The code for the following steps are contained in the IPython notebook located in "./CarND-Vehicle-Detection.ipynb". 

**Histogram of Oriented Gradients (HOG)**

In code cell 2 of the Ipython notebook , I loaded the provided the `vehicle` and `non-vehicle` images into cars and not_cars arrays respectively.  Here is an example of one of each of the `vehicle` and `non-vehicle` classes:

![alt text][image1]

In code cell 4-5, I explored various color spaces of a randomly selected car and non car image using `explore_colorspaces_HOG` function and computed the HOG of each colorspace using `skimage.hog()` function with  different `skimage.hog()` parameters (`orientations`, `pixels_per_cell`, and `cells_per_block`). I displayed the images to get a feel for what the `skimage.hog()` output looks like.

Here is an example using the `YCrCb` color space and HOG parameters of `orientations=8`, `pixels_per_cell=(8, 8)` and `cells_per_block=(2, 2)`:

![alt text][image2a]
![alt text][image2b]
![alt text][image2c]
![alt text][image2d]

I tried various combinations of parameters and selected the following combination `orientations=8`, `pixels_per_cell=(8, 8)` and `cells_per_block=(2, 2)`. This combination properly captured unique features of vehicles in images. 

**Color Histograms**

From code cell 6 - 16, I explored various color histograms of colorspaces to determine which properly clusters car pixels.The Saturation plane in the HSV color space performs well in clustering car pixels.Below is a test image and its color histograms visualized in a HSV 3-D plot:


![alt text][image3a]
![alt text][image3b]




**Train Classifier**

In code cell 19, I trained a SVM classifier with the following parameters C=10.0, kernel='linear'. The dataset fed into the classifier was generated by concatenating the Hog features, color histograms and spatial features(bin=32) of each image in the cars and not_cars arrays. I shuffled the data set and split it into train and test sets with a 80:20 ratio. After training the SVM classifer I got the following output:

```
Using: 9 orientations 8 pixels per cell and 2 cells per block
Feature vector length: 8460
138.15 Seconds to train SVC...
Test Accuracy of SVC =  0.9879
```

**Sliding Window Search**

In code cell 20, I implemented a sliding window method called `find_cars`.I explored various parameter combinations and found that the following parameter gave the best result :

```
Given that the shape of image is (720,1280)

image = image
ystart = int(image.shape[0]/2.0)
ystop = int(image.shape[0] - 32)
scale = 1.5
X_scaler = scaled featues
svc = trained classifier
orient = 9
pix_per_cell = 8
cell_per_block = 2
spatial_size = (32,32)
hist_bins = 32
```

In code cell 21, I also implemented a `add_heat` function to generate a heat map of detected vehicles. The following shows bounding boxes on detected vehicles  for test images using sliding window and their corresponding heatmaps:

![alt text][image4a]
![alt text][image4b]
![alt text][image4c]
![alt text][image4d]
![alt text][image4e]
![alt text][image4f]

The implemented sliding window search method `find_cars`, generally performs well in detecting vehicles in images. Though, it also classifies dark spots as vehicles.


**Video Implementation**

In  code cell 25, I implemented a pipeline `process_image` function which takes in an image as a parameter and ouputs an image with bounding boxes highlighting detected vehicles.
Below is a link to a video with each of its frame passed throught the pipeline:

![alt text][image5]

Here's a [link to the processed video][video]

**Discussion**

There were some challenges encountered while implementing the pipeline. Vehicles were not detected all the time and there where several false positives. To improve the performance of the pipeline, I averaged every five frames of the video and set a threshould (using `apply_threshold` function) to remove regions with low heat intensity.This outputs a more consistent bounding box for detected vehicles.To remove false positives, I excluded bounding boxes with width or height less than 50m. 

The pipeline performed generally well in detecting vehicles but the trained classifier sometimes identifies dark spots as vehicles thus creating false positives. To tackle this problem, I would train a better classifier either by improving the quality of the dataset , get more dataset or use an ensemble of classifiers.





