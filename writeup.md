
---

**Vehicle Detection Project**

The goals / steps of this project are the following:

* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images 
* Apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector. 
* train a classifier Linear SVM classifier
* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.
* Run pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.
* Estimate a bounding box for vehicles detected.

[//]: # (Image References)
[image1]: ./output_images/car_not_car.png
[image2a]: ./output_images/HOG_example_1.jpg
[image2b]: ./output_images/HOG_example_2.jpg
[image2c]: ./output_images/HOG_example_3.jpg
[image2d]: ./output_images/HOG_example_4.jpg
[image3a]: ./colorspace_exploration/000275.png
[image3b]: ./colorspace_exploration/HSV_3D_plot.png
[image4a]: ./output_images/test1.jpg
[image4b]: ./output_images/test2.jpg
[image4c]: ./output_images/test3.jpg
[image4d]: ./output_images/test4.jpg
[image4e]: ./output_images/test5.jpg
[image4f]: ./output_images/test6.jpg
[image5]: ./car_detection2.gif "Video"
[video1]: ./car_detection2.mp4

The code for the following steps are contained in the IPython notebook located in "./CarND-Vehicle-Detection.ipynb". 

**Histogram of Oriented Gradients (HOG)**

In code cell 2 of the Ipython notebook , I read in the provided the `vehicle` and `non-vehicle` images into cars and not_cars arrays respectively.  Here is an example of one of each of the `vehicle` and `non-vehicle` classes:

![alt text][image1]

In code cell 5, I explored various color spaces of a randomly selected car and non car image using `explore_colorspaces_HOG` function and computed the HOG of each colorspace using `skimage.hog()` function with  different `skimage.hog()` parameters (`orientations`, `pixels_per_cell`, and `cells_per_block`). I displayed the images to get a feel for what the `skimage.hog()` output looks like.

Here is an example using the `YCrCb` color space and HOG parameters of `orientations=8`, `pixels_per_cell=(8, 8)` and `cells_per_block=(2, 2)`:

![alt text][image2a]
![alt text][image2b]
![alt text][image2c]
![alt text][image2d]

I tried various combinations of parameters and selected the following combination `orientations=8`, `pixels_per_cell=(8, 8)` and `cells_per_block=(2, 2)`. This combination properly captured unique features of vehicles in images. 

**Color Histograms**

From code cell 6 - 12, I explored various color histograms of colorspaces to determine which properly clusters car pixels.The Saturation plane in the HSV color space performs well in clustering car pixels.Below is a test image and its color histograms visualized in a HSV 3-D plot:


![alt text][image3a]
![alt text][image3b]




**Train Classifier**

In code cell 15, I trained a SVM classifier with the following parameters C=10.0, kernel='linear'. The dataset fed into the classifier was generated by concatenating the Hog features, color histograms and spatial features of each image in the cars and not_cars arrays. After tarining the SVM classifer i got the following output:

```
Using: 9 orientations 8 pixels per cell and 2 cells per block
Feature vector length: 8460
147.62 Seconds to train SVC...
Test Accuracy of SVC =  0.9924
```

**Sliding Window Search**

####1. Describe how (and identify where in your code) you implemented a sliding window search.  How did you decide what scales to search and how much to overlap windows?

In code cell 16, I implemented a sliding window method called `find_cars`.I explored various parameter combinations and found that the following parameter gave the best result :

```
Given that the shape of image is (720,1280)

image = image
ystart = int(image.shape[0]/2.0)
ystop = int(image.shape[0] - 32)
scale = 1.5
X_scaler = scaled featues
svc = trained classifier
orient = 9
pix_per_cell = 8
cell_per_block = 2
spatial_size = (32,32)
hist_bins = 32
```

In code cell 17, I also implemented a `add_heat` function to generate a heat map of detected vehicles. The following shows test images and corresponding detections using sliding windows and heatmaps:

![alt text][image4a]
![alt text][image4b]
![alt text][image4c]
![alt text][image4d]
![alt text][image4e]
![alt text][image4f]

The implemented sliding window search method `find_cars`, generally performs well in detecting vehicles images.Though, it fails to detect vehicles that a further away in an image.


**Video Implementation**

####1. Provide a link to your final video output.  Your pipeline should perform reasonably well on the entire project video (somewhat wobbly or unstable bounding boxes are ok as long as you are identifying the vehicles most of the time with minimal false positives.)

In  code cell 20, I implemented a pipeline `process_image` function which takes an image and ouputs an image with a bounding box(es) highlighting detected vehicle(s).
Below is a link to a video with each of its frame passed throught the pipeline:

![alt text][image5]

Here's a [link to the processed video][video]

**Discussion**

There were some challenges encountered while implementing the pipeline. Vehicles were not detected all the time and there where several false positives. To improve the performance of the pipeline, I averaged every five frames of the video and set a threshould to remove less frequent bounding box(es).This outputs a more consistent bounding box for detected vehicles.To remove false positives I excluded bounding boxes with width or height less than 50m. 




####1. Briefly discuss any problems / issues you faced in your implementation of this project.  Where will your pipeline likely fail?  What could you do to make it more robust?

Here I'll talk about the approach I took, what techniques I used, what worked and why, where the pipeline might fail and how I might improve it if I were going to pursue this project further.  




